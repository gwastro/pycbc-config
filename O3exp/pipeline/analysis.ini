; PyCBC configuration for BNS-NSBH-BBH search on Advanced LIGO-Virgo data
;
; Documentation for running the workflow generator is here:
;
;    http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/pycbc_make_coinc_search_workflow.html



[workflow]
; http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/initialization.html
; file retention level can take 4 possible values 
; "all_files"    for debugging the pipeline
; "all_triggers" recommended for normal running
; "merged_triggers" used to rerun with file reuse for changes that do not affect
;                single-detector trigger sets but may affect coinc results
; "results"      used to rerun with file reuse to rerun with changes to plots
file-retention-level = all_triggers

[workflow-datafind]
; http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/datafind.html
datafind-method = AT_RUNTIME_SINGLE_FRAMES

; Look for times when the segment database says that data is analyzable, but
; no frame data exists on disk. If any frame data is missing, raise an error
datafind-check-segment-gaps = raise_error

; Stat each frame that datafind returns and fail if any frames are missing
datafind-check-frames-exist = raise_error

; Check to see if there are any frames on disk that are not covered in the
; segment_summary table for science segments. This must be "warn" when using
; C00 date, due to known discrepancies between the database segments and GDS
; frames, but should be set to "raise_error" for the final calibration.
datafind-check-segment-summary = warn

[workflow-segments]
; http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/segments.html
segments-method = ALL_SINGLE_IFO_TIME

[workflow-tmpltbank]
; See http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/template_bank.html
tmpltbank-method = PREGENERATED_BANK
; NOTE - This bank file may or may not be effectual depending on the data and its PSD!
tmpltbank-pregenerated-bank = https://raw.github.com/ligo-cbc/pycbc-config/7a437f481796ffa57a0cf73caa53a1ee641895ab/O2/bank/H1L1-HYPERBANK_SEOBNRv4v2_VARFLOW_THORNE-1163174417-604800.xml.gz

[workflow-splittable]
; http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/splittable.html
splittable-method = IN_WORKFLOW
splittable-exe-tag = splitbank

[workflow-splittable-full_data]
; empirically tuned on O2 OSG runtime data to give runtimes between 15 mins and 10 hours, mostly ~6 hours
splittable-num-banks = 32

[workflow-splittable-injections]
; empirically tuned on O2 OSG runtime data to give runtimes between a few mins and ~10 hours, mostly >30 minutes
splittable-num-banks = 8

[workflow-matchedfilter]
; http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/matched_filter.html
matchedfilter-method = WORKFLOW_INDEPENDENT_IFOS
min-analysis-segments = 1
min-analysis-length = 528
max-analysis-segments = 5
output-type = hdf
plot-throughput =

[workflow-coincidence]
; http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/hdf_coincidence.html
do-trigger-fitting =

[workflow-coincidence-full]
; For any given combination of ifos, time shifted coincidences are generated by
; shifting one ifo relative to all the rest
; The shifted ('pivot') ifo will be the one appearing first in this list
timeslide-precedence = H1, L1, V1, K1, I1
parallelization-factor = 20

[workflow-coincidence-inj]
parallelization-factor = 5

[workflow-psd]
parallelization-factor = 10

[workflow-gating]
; not clear if this has any meaning now - FIXME
gating-method = PREGENERATED_FILE

[workflow-results]
; number of levels of event hierarchical removal to perform
max-hierarchical-removal = 5

[llwadd]

[segments_from_cats]

[ligolw_combine_segments]

[splitbank]
; split the template bank up randomly between jobs to ensure equal run time
random-sort =
; set a seed so that the random split is deterministic
random-seed = 666

[inspiral]
; parameters for matched filtering

; sine-Gaussian chisq
sgchisq-snr-threshold = 6.0
sgchisq-locations = "mtotal>40:20-30,20-45,20-60,20-75,20-90,20-105,20-120"

; amount of buffer data for letting filters settle
pad-data = 8

; conditioning high-pass filter
strain-high-pass = 15

; working sample rate for matched filtering
sample-rate = 2048

; segmentation of the data
; start-pad must be long enough to contain a full BNS signal
segment-length = 512
segment-start-pad = 144
segment-end-pad = 16
; turn on zero-padding
allow-zero-padding =
; Taper the first and last second of data read in for zero padding
taper-data = 1

; estimation of the noise PSD and construction of the whitening filter
psd-estimation = median
psd-segment-length = 16
psd-segment-stride = 8
psd-inverse-length = 16
; 512s PSD length given by:
; 512s = psd-segment-length + (psd-num-segments - 1) * psd-segment-stride
psd-num-segments = 63

; Autogating options
autogating-threshold = 100
autogating-cluster = 0.5
autogating-width = 0.25
autogating-taper = 0.25
autogating-pad = 16

; starting frequency of matched filter integration
; low-frequency-cutoff is set to the minimum variable frequency in the bank,
; rounded down
enable-bank-start-frequency =
low-frequency-cutoff = 20

; template approximant
; switch to SEOBNRv4 templates as soon as we can (M >= 4)
approximant = 'SPAtmplt:mtotal<4' 'SEOBNRv4_ROM:else'
order = -1

; threshold for generating triggers
snr-threshold = 5.5

; method for clustering triggers over time
cluster-method = window
cluster-window = 1
cluster-function = symmetric

; signal-based vetoes
chisq-bins = "0.72*get_freq('fSEOBNRv4Peak',params.mass1,params.mass2,params.spin1z,params.spin2z)**0.7"
newsnr-threshold = 5

; options for reducing the computational cost and storage
filter-inj-only = 
injection-window = 4.5
processing-scheme = mkl

[inspiral-h1]
; Hanford specific matched-filter parameters
channel-name = ${workflow|h1-channel-name}

[inspiral-l1]
; Livingston specific matched-filter parameters
channel-name = ${workflow|l1-channel-name}

[inspiral-v1]
; Virgo specific matched-filter parameters
channel-name = ${workflow|v1-channel-name}

[calculate_psd]
cores = 4
low-frequency-cutoff = ${inspiral|low-frequency-cutoff}
pad-data = ${inspiral|pad-data}
strain-high-pass = ${inspiral|strain-high-pass}
sample-rate = ${inspiral|sample-rate}
segment-length = ${inspiral|segment-length}
segment-start-pad = ${inspiral|segment-start-pad}
segment-end-pad = ${inspiral|segment-end-pad}
psd-estimation = ${inspiral|psd-estimation}
psd-segment-length = ${inspiral|psd-segment-length}
psd-segment-stride = ${inspiral|psd-segment-stride}
psd-num-segments = ${inspiral|psd-num-segments}
taper-data = ${inspiral|taper-data}
autogating-threshold = ${inspiral|autogating-threshold}
autogating-cluster = ${inspiral|autogating-cluster}
autogating-width = ${inspiral|autogating-width}
autogating-taper = ${inspiral|autogating-taper}
autogating-pad = ${inspiral|autogating-pad}

[merge_psds]

[calculate_psd-h1]
channel-name = ${workflow|h1-channel-name}

[calculate_psd-l1]
channel-name = ${workflow|l1-channel-name}

[calculate_psd-v1]
channel-name = ${workflow|v1-channel-name}

[hdf_trigger_merge]

[bank2hdf]

[fit_by_template]
fit-function = exponential
sngl-stat = newsnr_sgveto
stat-threshold = 6.
prune-param = mtotal
log-prune-param =
prune-bins = 2
prune-number = 2

[fit_over_param]
fit-param = template_duration
; f_low required to calculate template duration to smooth the fit over
f-lower = ${inspiral|low-frequency-cutoff}
log-param =
regression-method = tricube
smoothing-width = 0.2

[distribute_background_bins]

[multiifo_coinc]
; additional time (in seconds) to add to light-travel time to construct time coincidence window
; only 2- or multi-ifo coinc times are considered to construct the time shift background ("strict coincidence")
coinc-threshold = 0.005
ranking-statistic = newsnr

[multiifo_coinc-full]
; time-slide interval in seconds
timeslide-interval = 0.1
; reduction factor to make lightning bolts for IFAR plots
decimation-factor = 5000
; always store time slide coincs with a stat above specified value
loudest-keep-value = 8.5

[coinc-fullinj&coinc-injfull]
; perform little-dog analysis for software injections
timeslide-interval = ${multiifo_coinc-full|timeslide-interval}
cluster-window = ${statmap|cluster-window}
; keep only coincs with a stat above specified value in injection little-dog analysis
loudest-keep-value = 8.5

[statmap]
max-hierarchical-removal = ${workflow-results|max-hierarchical-removal}
hierarchical-removal-against = exclusive

[statmap&statmap_inj]
; time window (in seconds) used to remove triggers around zero-lag coincidences
veto-window = 0.100
; cluster each slide separately over a 10 second window
cluster-window = 10.0

[combine_statmap]
cluster-window = ${statmap|cluster-window}

[foreground_censor]

[hdfinjfind]
; time in seconds within which a trigger must fall to be associated with an injection
injection-window = 2.0
optimal-snr-column = H1:alpha1 L1:alpha2 V1:alpha3
